# APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

YouTube.py3ã®å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ãªèª¬æ˜ã§ã™ã€‚å®Ÿè£…æ¸ˆã¿ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ©Ÿèƒ½åˆ¥ã«åˆ†é¡ã—ã¦èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ“š ç›®æ¬¡

- [åŸºæœ¬ã‚¯ãƒ©ã‚¹](#åŸºæœ¬ã‚¯ãƒ©ã‚¹)
- [åŸºæœ¬æƒ…å ±å–å¾—](#åŸºæœ¬æƒ…å ±å–å¾—)
- [æ¤œç´¢æ©Ÿèƒ½](#æ¤œç´¢æ©Ÿèƒ½)
- [ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆç®¡ç†](#ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆç®¡ç†)
- [ã‚³ãƒ¡ãƒ³ãƒˆç®¡ç†](#ã‚³ãƒ¡ãƒ³ãƒˆç®¡ç†)
- [ãƒãƒ£ãƒ³ãƒãƒ«ç®¡ç†](#ãƒãƒ£ãƒ³ãƒãƒ«ç®¡ç†)
- [å‹•ç”»ç®¡ç†](#å‹•ç”»ç®¡ç†)
- [ãƒ©ã‚¤ãƒ–ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°](#ãƒ©ã‚¤ãƒ–ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
- [å­—å¹•ç®¡ç†](#å­—å¹•ç®¡ç†)
- [ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç®¡ç†](#ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç®¡ç†)
- [ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±](#ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±)
- [ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½](#ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½)
- [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
- [ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³é›†](#ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³é›†)

---

## åŸºæœ¬ã‚¯ãƒ©ã‚¹

### YouTubeAPI

```python
class YouTubeAPI(api_key: str)
```

YouTube Data API v3ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `api_key` (str): YouTube Data API v3ã®APIã‚­ãƒ¼
  - [Google Cloud Console](https://console.cloud.google.com/)ã§å–å¾—å¯èƒ½
  - YouTube Data API v3ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™

**ä¾‹å¤–:**
- `YouTubeAPIError`: APIã‚­ãƒ¼ãŒç„¡åŠ¹ãªå ´åˆ

**åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹:**
```python
from youtube_py3 import YouTubeAPI
import os

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆæ¨å¥¨ï¼‰
api_key = os.getenv('YOUTUBE_API_KEY')
yt = YouTubeAPI(api_key)

# ç›´æ¥æŒ‡å®šã‚‚å¯èƒ½ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«æ³¨æ„ï¼‰
# yt = YouTubeAPI('your_api_key_here')
```

**APIã‚­ãƒ¼ã®è¨­å®šæ–¹æ³•:**
```bash
# Windows
set YOUTUBE_API_KEY=your_api_key_here

# macOS/Linux
export YOUTUBE_API_KEY=your_api_key_here
```

### YouTubeAPIError

```python
class YouTubeAPIError(Exception)
```

YouTube APIé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ä¾‹å¤–ã‚¯ãƒ©ã‚¹ã€‚

**ãƒ¡ã‚½ãƒƒãƒ‰:**
- `is_quota_exceeded()`: ã‚¯ã‚©ãƒ¼ã‚¿è¶…éã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
- `is_api_key_invalid()`: APIã‚­ãƒ¼ç„¡åŠ¹ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
- `is_not_found()`: ãƒªã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
- `is_forbidden()`: ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
- `get_suggested_action()`: ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
try:
    video = yt.get_video_info("invalid_id")
except YouTubeAPIError as e:
    print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã«å¿œã˜ãŸè©³ç´°ãªå¯¾å‡¦
    if e.is_quota_exceeded():
        print("âŒ APIã‚¯ã‚©ãƒ¼ã‚¿ãŒåˆ¶é™ã‚’è¶…ãˆã¾ã—ãŸ")
        print("ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:", e.get_suggested_action())
        # æ˜æ—¥ã¾ã§å¾…ã¤ã‹ã€èª²é‡‘ã‚’æ¤œè¨
        
    elif e.is_api_key_invalid():
        print("âŒ APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™")
        print("ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:", e.get_suggested_action())
        # APIã‚­ãƒ¼ã‚’ç¢ºèªãƒ»å†ç”Ÿæˆ
        
    elif e.is_not_found():
        print("âŒ æŒ‡å®šã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:", e.get_suggested_action())
        # IDã‚’ç¢ºèª
        
    elif e.is_forbidden():
        print("âŒ ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:", e.get_suggested_action())
        # éå…¬é–‹å‹•ç”»ã®å¯èƒ½æ€§
```

---

## åŸºæœ¬æƒ…å ±å–å¾—

### check_quota_usage()

```python
def check_quota_usage() -> bool
```

APIã‚¯ã‚©ãƒ¼ã‚¿ã®ä½¿ç”¨é‡ã‚’ç¢ºèªã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã€‚

**æˆ»ã‚Šå€¤:**
- `bool`: APIã‚­ãƒ¼ãŒæœ‰åŠ¹ã‹ã©ã†ã‹

**ä¾‹å¤–:**
- `YouTubeAPIError`: APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯åˆ¶é™ã•ã‚Œã¦ã„ã‚‹å ´åˆ

**å®Ÿè·µçš„ãªä½¿ç”¨ä¾‹:**
```python
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã®ç¢ºèª
try:
    if yt.check_quota_usage():
        print("âœ… APIã‚­ãƒ¼ã¯æœ‰åŠ¹ã§ã™ã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œ
    else:
        print("âŒ APIã‚­ãƒ¼ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
except YouTubeAPIError as e:
    print(f"APIã‚¨ãƒ©ãƒ¼: {e}")
    
# ãƒãƒƒãƒå‡¦ç†ã§ã®å®šæœŸç¢ºèª
import time

def safe_batch_process():
    for i, item in enumerate(batch_items):
        if i % 10 == 0:  # 10ä»¶ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
            if not yt.check_quota_usage():
                print("ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                break
        
        # å®Ÿéš›ã®å‡¦ç†
        process_item(item)
        time.sleep(0.1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
```

### get_channel_info()

```python
def get_channel_info(channel_id: str) -> dict
```

ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `channel_id` (str): YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã®ID
  - URLã‹ã‚‰æŠœãå‡ºã™: `https://www.youtube.com/channel/UC_x5XG1OV2P6uZZ5FSM9Ttw`
  - ã¾ãŸã¯ `@username` å½¢å¼ã‚‚å¯¾å¿œäºˆå®š

**æˆ»ã‚Šå€¤ã®æ§‹é€ :**
```python
{
    'snippet': {
        'title': 'ãƒãƒ£ãƒ³ãƒãƒ«å',
        'description': 'ãƒãƒ£ãƒ³ãƒãƒ«èª¬æ˜',
        'customUrl': 'ã‚«ã‚¹ã‚¿ãƒ URL',
        'publishedAt': '2020-01-01T00:00:00Z',
        'thumbnails': { ... },
        'country': 'JP'
    },
    'statistics': {
        'viewCount': '1234567',
        'subscriberCount': '12345',
        'videoCount': '100'
    }
}
```

**ä¾‹å¤–:**
- `YouTubeAPIError`: ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
# åŸºæœ¬çš„ãªæƒ…å ±å–å¾—
channel_id = "UC_x5XG1OV2P6uZZ5FSM9Ttw"
try:
    channel = yt.get_channel_info(channel_id)
    
    # åŸºæœ¬æƒ…å ±ã®è¡¨ç¤º
    print(f"ğŸ“º ãƒãƒ£ãƒ³ãƒãƒ«å: {channel['snippet']['title']}")
    print(f"ğŸ“… é–‹è¨­æ—¥: {channel['snippet']['publishedAt'][:10]}")
    print(f"ğŸŒ å›½: {channel['snippet'].get('country', 'N/A')}")
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    stats = channel['statistics']
    print(f"ğŸ‘¥ ç™»éŒ²è€…æ•°: {int(stats['subscriberCount']):,}")
    print(f"ğŸ“¹ å‹•ç”»æ•°: {int(stats['videoCount']):,}")
    print(f"ğŸ‘€ ç·å†ç”Ÿå›æ•°: {int(stats['viewCount']):,}")
    
    # ã‚µãƒ ãƒã‚¤ãƒ«å–å¾—
    thumbnail_url = channel['snippet']['thumbnails']['high']['url']
    print(f"ğŸ–¼ï¸ ã‚µãƒ ãƒã‚¤ãƒ«: {thumbnail_url}")
    
except YouTubeAPIError as e:
    if e.is_not_found():
        print("âŒ æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")

# URLã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã®ä¾‹
def extract_channel_id(url: str) -> str:
    """YouTube URLã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’æŠ½å‡º"""
    import re
    patterns = [
        r'youtube\.com/channel/([a-zA-Z0-9_-]+)',
        r'youtube\.com/c/([a-zA-Z0-9_-]+)',
        r'youtube\.com/@([a-zA-Z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    raise ValueError("æœ‰åŠ¹ãªYouTubeãƒãƒ£ãƒ³ãƒãƒ«URLã§ã¯ã‚ã‚Šã¾ã›ã‚“")

# ä½¿ç”¨ä¾‹
channel_url = "https://www.youtube.com/channel/UC_x5XG1OV2P6uZZ5FSM9Ttw"
channel_id = extract_channel_id(channel_url)
channel_info = yt.get_channel_info(channel_id)
```

### get_video_info()

```python
def get_video_info(video_id: str) -> dict
```

å‹•ç”»æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `video_id` (str): YouTubeå‹•ç”»ã®ID
  - URLã‹ã‚‰æŠ½å‡º: `https://www.youtube.com/watch?v=dQw4w9WgXcQ` â†’ `dQw4w9WgXcQ`

**æˆ»ã‚Šå€¤ã®æ§‹é€ :**
```python
{
    'snippet': {
        'title': 'å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«',
        'description': 'å‹•ç”»èª¬æ˜',
        'channelTitle': 'ãƒãƒ£ãƒ³ãƒãƒ«å',
        'publishedAt': '2020-01-01T00:00:00Z',
        'thumbnails': { ... },
        'tags': ['ã‚¿ã‚°1', 'ã‚¿ã‚°2'],
        'categoryId': '10',
        'duration': 'PT4M33S'  # ISO 8601å½¢å¼
    },
    'statistics': {
        'viewCount': '1234567',
        'likeCount': '12345',
        'commentCount': '678'
    }
}
```

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
import re
from datetime import datetime

def extract_video_id(url: str) -> str:
    """YouTube URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡º"""
    patterns = [
        r'youtube\.com/watch\?v=([a-zA-Z0-9_-]+)',
        r'youtu\.be/([a-zA-Z0-9_-]+)',
        r'youtube\.com/embed/([a-zA-Z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    raise ValueError("æœ‰åŠ¹ãªYouTubeå‹•ç”»URLã§ã¯ã‚ã‚Šã¾ã›ã‚“")

def parse_duration(duration: str) -> str:
    """ISO 8601æ™‚é–“å½¢å¼ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
    import re
    pattern = r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?'
    match = re.match(pattern, duration)
    
    if not match:
        return "ä¸æ˜"
    
    hours, minutes, seconds = match.groups()
    hours = int(hours) if hours else 0
    minutes = int(minutes) if minutes else 0
    seconds = int(seconds) if seconds else 0
    
    if hours > 0:
        return f"{hours}æ™‚é–“{minutes}åˆ†{seconds}ç§’"
    elif minutes > 0:
        return f"{minutes}åˆ†{seconds}ç§’"
    else:
        return f"{seconds}ç§’"

# å®Ÿè·µçš„ãªä½¿ç”¨ä¾‹
video_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"
video_id = extract_video_id(video_url)

try:
    video = yt.get_video_info(video_id)
    snippet = video['snippet']
    stats = video['statistics']
    
    # åŸºæœ¬æƒ…å ±
    print(f"ğŸ¬ ã‚¿ã‚¤ãƒˆãƒ«: {snippet['title']}")
    print(f"ğŸ“º ãƒãƒ£ãƒ³ãƒãƒ«: {snippet['channelTitle']}")
    print(f"ğŸ“… å…¬é–‹æ—¥: {snippet['publishedAt'][:10]}")
    print(f"â±ï¸ å†ç”Ÿæ™‚é–“: {parse_duration(snippet.get('duration', 'PT0S'))}")
    
    # çµ±è¨ˆæƒ…å ±
    print(f"ğŸ‘€ å†ç”Ÿå›æ•°: {int(stats['viewCount']):,}")
    print(f"ğŸ‘ ã„ã„ã­æ•°: {int(stats.get('likeCount', 0)):,}")
    print(f"ğŸ’¬ ã‚³ãƒ¡ãƒ³ãƒˆæ•°: {int(stats.get('commentCount', 0)):,}")
    
    # ã‚¿ã‚°æƒ…å ±
    if 'tags' in snippet:
        print(f"ğŸ·ï¸ ã‚¿ã‚°: {', '.join(snippet['tags'][:5])}...")
    
    # ã‚µãƒ ãƒã‚¤ãƒ«
    thumbnail = snippet['thumbnails']['maxres']['url']
    print(f"ğŸ–¼ï¸ ã‚µãƒ ãƒã‚¤ãƒ«: {thumbnail}")
    
    # èª¬æ˜æ–‡ã®ä¸€éƒ¨
    description = snippet['description']
    if len(description) > 100:
        print(f"ğŸ“ èª¬æ˜: {description[:100]}...")
    else:
        print(f"ğŸ“ èª¬æ˜: {description}")
        
except YouTubeAPIError as e:
    if e.is_not_found():
        print("âŒ æŒ‡å®šã•ã‚ŒãŸå‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå‰Šé™¤æ¸ˆã¿ã¾ãŸã¯éå…¬é–‹ï¼‰")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")

# è¤‡æ•°å‹•ç”»ã®ä¸€æ‹¬å–å¾—ä¾‹
def get_multiple_videos(video_ids: list) -> list:
    """è¤‡æ•°ã®å‹•ç”»æƒ…å ±ã‚’åŠ¹ç‡çš„ã«å–å¾—"""
    videos = []
    for video_id in video_ids:
        try:
            video = yt.get_video_info(video_id)
            videos.append(video)
        except YouTubeAPIError as e:
            print(f"å‹•ç”» {video_id} ã®å–å¾—ã«å¤±æ•—: {e}")
            continue
    return videos

video_ids = ["dQw4w9WgXcQ", "9bZkp7q19f0", "invalid_id"]
videos = get_multiple_videos(video_ids)
print(f"âœ… {len(videos)}ä»¶ã®å‹•ç”»æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
```

### get_channel_statistics_only()

```python
def get_channel_statistics_only(channel_id: str) -> dict
```

ãƒãƒ£ãƒ³ãƒãƒ«ã®çµ±è¨ˆæƒ…å ±ã®ã¿ã‚’åŠ¹ç‡çš„ã«å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `channel_id` (str): YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã®ID

**æˆ»ã‚Šå€¤:**
- `dict`: çµ±è¨ˆæƒ…å ±ã®ã¿ï¼ˆã‚¯ã‚©ãƒ¼ã‚¿æ¶ˆè²»ã‚’æœ€å°åŒ–ï¼‰

**ä½¿ç”¨ä¾‹:**
```python
# å¤§é‡ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®çµ±è¨ˆã‚’åŠ¹ç‡çš„ã«å–å¾—
channel_ids = ["UC_x5XG1OV2P6uZZ5FSM9Ttw", "UC-lHJZR3Gqxm24_Vd_AJ5Yw"]

for channel_id in channel_ids:
    try:
        stats = yt.get_channel_statistics_only(channel_id)
        print(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ç™»éŒ²è€…æ•° {stats['subscriberCount']}")
    except YouTubeAPIError:
        print(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: å–å¾—å¤±æ•—")
```

**æ³¨æ„:**
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™ã€‚

### get_video_statistics_only()

```python
def get_video_statistics_only(video_id: str) -> dict
```

å‹•ç”»ã®çµ±è¨ˆæƒ…å ±ã®ã¿ã‚’åŠ¹ç‡çš„ã«å–å¾—ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `video_id` (str): YouTubeå‹•ç”»ã®ID

**æˆ»ã‚Šå€¤:**
- `dict`: çµ±è¨ˆæƒ…å ±ã®ã¿

**ä½¿ç”¨ä¾‹:**
```python
# å‹•ç”»ã®äººæ°—åº¦ã‚’ç´ æ—©ããƒã‚§ãƒƒã‚¯
video_id = "dQw4w9WgXcQ"
stats = yt.get_video_statistics_only(video_id)
print(f"å†ç”Ÿå›æ•°: {stats['viewCount']:,}")
```

**æ³¨æ„:**
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™ã€‚

---

## æ¤œç´¢æ©Ÿèƒ½

### search_videos()

```python
def search_videos(query: str, max_results: int = 5, order: str = "relevance") -> list
```

å‹•ç”»ã‚’æ¤œç´¢ã—ã¾ã™ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `query` (str): æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
  - æ—¥æœ¬èªã€è‹±èªå¯¾å¿œ
  - ANDæ¤œç´¢: `"Python AND æ©Ÿæ¢°å­¦ç¿’"`
  - ORæ¤œç´¢: `"Python OR JavaScript"`
  - é™¤å¤–: `"Python -Java"`
- `max_results` (int): å–å¾—ã™ã‚‹æœ€å¤§çµæœæ•°ï¼ˆ1-50ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
- `order` (str): ã‚½ãƒ¼ãƒˆé †åºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'relevance'ï¼‰
  - `'relevance'`: é–¢é€£åº¦é †ï¼ˆæ¨å¥¨ï¼‰
  - `'date'`: æŠ•ç¨¿æ—¥æ™‚é †ï¼ˆæ–°ã—ã„é †ï¼‰
  - `'rating'`: è©•ä¾¡é †
  - `'viewCount'`: å†ç”Ÿå›æ•°é †
  - `'title'`: ã‚¿ã‚¤ãƒˆãƒ«é †ï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ï¼‰

**æˆ»ã‚Šå€¤:**
å„å‹•ç”»æƒ…å ±ã‚’å«ã‚€ãƒªã‚¹ãƒˆ

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
# åŸºæœ¬çš„ãªæ¤œç´¢
videos = yt.search_videos("Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", max_results=10)
for i, video in enumerate(videos, 1):
    snippet = video['snippet']
    print(f"{i}. {snippet['title']}")
    print(f"   ãƒãƒ£ãƒ³ãƒãƒ«: {snippet['channelTitle']}")
    print(f"   å…¬é–‹æ—¥: {snippet['publishedAt'][:10]}")
    print()

# é«˜åº¦ãªæ¤œç´¢ä¾‹
def advanced_search_videos():
    """é«˜åº¦ãªå‹•ç”»æ¤œç´¢ã®ä¾‹"""
    
    # 1. æœ€æ–°ã®å‹•ç”»ã‚’æ¤œç´¢
    print("=== æœ€æ–°ã®Pythonå‹•ç”» ===")
    latest_videos = yt.search_videos(
        query="Python tutorial",
        max_results=5,
        order="date"
    )
    
    # 2. äººæ°—é †ã§æ¤œç´¢
    print("=== äººæ°—ã®AIå‹•ç”» ===")
    popular_videos = yt.search_videos(
        query="äººå·¥çŸ¥èƒ½ AI",
        max_results=5,
        order="viewCount"
    )
    
    # 3. ç‰¹å®šã®æ¡ä»¶ã§æ¤œç´¢
    print("=== æ©Ÿæ¢°å­¦ç¿’ã®å…¥é–€å‹•ç”» ===")
    ml_videos = yt.search_videos(
        query="æ©Ÿæ¢°å­¦ç¿’ å…¥é–€ -ä¸Šç´š",  # ä¸Šç´šã‚’é™¤å¤–
        max_results=10,
        order="relevance"
    )
    
    return latest_videos, popular_videos, ml_videos

# æ¤œç´¢çµæœã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
def filter_videos_by_duration(videos: list, min_duration_sec: int = 300):
    """æŒ‡å®šã—ãŸæœ€å°æ™‚é–“ä»¥ä¸Šã®å‹•ç”»ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    filtered = []
    for video in videos:
        try:
            # å‹•ç”»è©³ç´°ã‚’å–å¾—ã—ã¦æ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
            video_detail = yt.get_video_info(video['id']['videoId'])
            duration = video_detail['snippet'].get('duration', 'PT0S')
            
            # PT5M33S â†’ 333ç§’ã«å¤‰æ›
            import re
            pattern = r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?'
            match = re.match(pattern, duration)
            
            if match:
                hours, minutes, seconds = match.groups()
                total_seconds = (
                    (int(hours) if hours else 0) * 3600 +
                    (int(minutes) if minutes else 0) * 60 +
                    (int(seconds) if seconds else 0)
                )
                
                if total_seconds >= min_duration_sec:
                    filtered.append(video)
                    
        except Exception as e:
            print(f"å‹•ç”» {video['id']['videoId']} ã®è©³ç´°å–å¾—ã«å¤±æ•—: {e}")
            continue
            
    return filtered

# å®Ÿè·µçš„ãªæ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
search_results = yt.search_videos("Python ãƒ‡ãƒ¼ã‚¿åˆ†æ", max_results=20)
long_videos = filter_videos_by_duration(search_results, min_duration_sec=600)  # 10åˆ†ä»¥ä¸Š
print(f"10åˆ†ä»¥ä¸Šã®å‹•ç”»: {len(long_videos)}ä»¶")
```

### search_channels()

```python
def search_channels(query: str, max_results: int = 5, order: str = "relevance") -> list
```

ãƒãƒ£ãƒ³ãƒãƒ«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
# ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ç³»ãƒãƒ£ãƒ³ãƒãƒ«ã®æ¤œç´¢
channels = yt.search_channels("ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° åˆå¿ƒè€…", max_results=10)

print("=== ãŠã™ã™ã‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒãƒ£ãƒ³ãƒãƒ« ===")
for i, channel in enumerate(channels, 1):
    snippet = channel['snippet']
    print(f"{i}. {snippet['title']}")
    print(f"   èª¬æ˜: {snippet['description'][:100]}...")
    print(f"   ãƒãƒ£ãƒ³ãƒãƒ«ID: {channel['id']['channelId']}")
    
    # ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°ã‚’å–å¾—
    try:
        channel_detail = yt.get_channel_info(channel['id']['channelId'])
        stats = channel_detail['statistics']
        print(f"   ğŸ“Š ç™»éŒ²è€…æ•°: {int(stats['subscriberCount']):,}")
        print(f"   ğŸ“¹ å‹•ç”»æ•°: {int(stats['videoCount']):,}")
    except YouTubeAPIError:
        print("   ğŸ“Š çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—")
    print()

# ãƒãƒ£ãƒ³ãƒãƒ«ã®è©³ç´°æƒ…å ±ä»˜ãæ¤œç´¢çµæœ
def search_channels_with_details(query: str, max_results: int = 5):
    """ãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢çµæœã«è©³ç´°æƒ…å ±ã‚’ä»˜åŠ """
    channels = yt.search_channels(query, max_results)
    detailed_channels = []
    
    for channel in channels:
        try:
            channel_id = channel['id']['channelId']
            detail = yt.get_channel_info(channel_id)
            
            # åŸºæœ¬æƒ…å ±ã¨è©³ç´°æƒ…å ±ã‚’ãƒãƒ¼ã‚¸
            enhanced_channel = {
                'basic_info': channel,
                'detailed_info': detail,
                'subscriber_count': int(detail['statistics']['subscriberCount']),
                'video_count': int(detail['statistics']['videoCount'])
            }
            detailed_channels.append(enhanced_channel)
            
        except YouTubeAPIError as e:
            print(f"ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    # ç™»éŒ²è€…æ•°ã§ã‚½ãƒ¼ãƒˆ
    detailed_channels.sort(key=lambda x: x['subscriber_count'], reverse=True)
    return detailed_channels

# ä½¿ç”¨ä¾‹
tech_channels = search_channels_with_details("æŠ€è¡“ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", max_results=10)
print("ç™»éŒ²è€…æ•°é †:")
for channel in tech_channels:
    title = channel['basic_info']['snippet']['title']
    subscribers = channel['subscriber_count']
    print(f"- {title}: {subscribers:,}äºº")
```

### search_playlists()

```python
def search_playlists(query: str, max_results: int = 5, order: str = "relevance") -> list
```

ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’æ¤œç´¢ã—ã¾ã™ã€‚

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
# å­¦ç¿’ç”¨ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®æ¤œç´¢
playlists = yt.search_playlists("Python å…¥é–€ è¬›åº§", max_results=15)

print("=== Pythonå­¦ç¿’ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ ===")
for i, playlist in enumerate(playlists, 1):
    snippet = playlist['snippet']
    print(f"{i}. {snippet['title']}")
    print(f"   ãƒãƒ£ãƒ³ãƒãƒ«: {snippet['channelTitle']}")
    print(f"   ä½œæˆæ—¥: {snippet['publishedAt'][:10]}")
    
    # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®è©³ç´°ã‚’å–å¾—
    try:
        playlist_id = playlist['id']['playlistId']
        playlist_videos = yt.get_playlist_videos(playlist_id, max_results=1)
        
        if playlist_videos:
            video_count = len(yt.get_playlist_videos(playlist_id, max_results=50))
            print(f"   ğŸ“¹ å‹•ç”»æ•°: {video_count}æœ¬")
            
    except YouTubeAPIError:
        print("   ğŸ“¹ å‹•ç”»æ•°: å–å¾—å¤±æ•—")
    print()

# ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåˆ†ææ©Ÿèƒ½
def analyze_playlist(playlist_id: str):
    """ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’è©³ç´°åˆ†æ"""
    try:
        # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåŸºæœ¬æƒ…å ±
        playlist_info = yt.get_playlist_info(playlist_id)
        videos = yt.get_playlist_videos(playlist_id, max_results=200)
        
        # åˆ†æãƒ‡ãƒ¼ã‚¿ã®åé›†
        channels = {}
        total_views = 0
        total_likes = 0
        publish_dates = []
        
        print("ğŸ“Š ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåˆ†æä¸­...")
        for i, video in enumerate(videos):
            snippet = video['snippet']
            
            # ãƒãƒ£ãƒ³ãƒãƒ«é›†è¨ˆ
            channel = snippet['channelTitle']
            channels[channel] = channels.get(channel, 0) + 1
            
            # çµ±è¨ˆæƒ…å ±å–å¾—
            try:
                video_id = snippet['resourceId']['videoId']
                video_detail = yt.get_video_info(video_id)
                stats = video_detail['statistics']
                
                total_views += int(stats['viewCount'])
                total_likes += int(stats.get('likeCount', 0))
                publish_dates.append(snippet['publishedAt'])
                
            except YouTubeAPIError:
                continue
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % 10 == 0:
                print(f"  å‡¦ç†æ¸ˆã¿: {i + 1}/{len(videos)}")
        
        # åˆ†æçµæœ
        analysis = {
            'playlist_title': playlist_info['snippet']['title'],
            'total_videos': len(videos),
            'total_views': total_views,
            'total_likes': total_likes,
            'average_views': total_views // len(videos) if videos else 0,
            'unique_channels': len(channels),
            'top_channels': sorted(channels.items(), key=lambda x: x[1], reverse=True)[:5],
            'date_range': {
                'oldest': min(publish_dates) if publish_dates else None,
                'newest': max(publish_dates) if publish_dates else None
            }
        }
        
        return analysis
        
    except YouTubeAPIError as e:
        return {'error': str(e)}

# ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåˆ†æã®å®Ÿè¡Œ
analysis = analyze_playlist("PLxyz123")

if 'error' not in analysis:
    print("=== ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåˆ†æçµæœ ===")
    print(f"ğŸ“ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {analysis['playlist_title']}")
    print(f"ğŸ“¹ å‹•ç”»æ•°: {analysis['total_videos']}")
    print(f"ğŸ‘€ ç·å†ç”Ÿå›æ•°: {analysis['total_views']:,}")
    print(f"ğŸ‘ ç·ã„ã„ã­æ•°: {analysis['total_likes']:,}")
    print(f"ğŸ“Š å¹³å‡å†ç”Ÿå›æ•°: {analysis['average_views']:,}")
    print(f"ğŸ“º é–¢é€£ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {analysis['unique_channels']}")
    
    print("\nğŸ” ä¸Šä½ãƒãƒ£ãƒ³ãƒãƒ«:")
    for channel, count in analysis['top_channels']:
        print(f"  - {channel}: {count}æœ¬")
    
    if analysis['date_range']['oldest']:
        print(f"\nğŸ“… æœŸé–“: {analysis['date_range']['oldest'][:10]} ï½ {analysis['date_range']['newest'][:10]}")

# ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
def export_playlist_to_csv(playlist_id: str, filename: str = None):
    """ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    import csv
    from datetime import datetime
    
    if not filename:
        filename = f"playlist_{playlist_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    
    try:
        videos = yt.get_playlist_videos(playlist_id, max_results=500)
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['é †ç•ª', 'ã‚¿ã‚¤ãƒˆãƒ«', 'ãƒãƒ£ãƒ³ãƒãƒ«', 'å‹•ç”»ID', 'URL', 'è¿½åŠ æ—¥']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for i, video in enumerate(videos, 1):
                snippet = video['snippet']
                video_id = snippet['resourceId']['videoId']
                
                writer.writerow({
                    'é †ç•ª': i,
                    'ã‚¿ã‚¤ãƒˆãƒ«': snippet['title'],
                    'ãƒãƒ£ãƒ³ãƒãƒ«': snippet['channelTitle'],
                    'å‹•ç”»ID': video_id,
                    'URL': f"https://www.youtube.com/watch?v={video_id}",
                    'è¿½åŠ æ—¥': snippet['publishedAt'][:10]
                })
        
        print(f"âœ… ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’ {filename} ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
        return filename
        
    except Exception as e:
        print(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®å®Ÿè¡Œ
export_playlist_to_csv("PLxyz123")
```

### get_channel_playlists()

```python
def get_channel_playlists(channel_id: str, max_results: int = 50) -> list
```

ãƒãƒ£ãƒ³ãƒãƒ«ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆä¸€è¦§ã‚’å–å¾—ã—ã¾ã™ã€‚

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
# ãƒãƒ£ãƒ³ãƒãƒ«ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆä¸€è¦§ã‚’å–å¾—
channel_id = "UC_x5XG1OV2P6uZZ5FSM9Ttw"

try:
    playlists = yt.get_channel_playlists(channel_id, max_results=100)
    
    print(f"ğŸ“º ãƒãƒ£ãƒ³ãƒãƒ«ã« {len(playlists)} å€‹ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆãŒã‚ã‚Šã¾ã™")
    print()
    
    # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®è©³ç´°è¡¨ç¤º
    for i, playlist in enumerate(playlists, 1):
        snippet = playlist['snippet']
        
        print(f"{i}. {snippet['title']}")
        print(f"   ğŸ“… ä½œæˆæ—¥: {snippet['publishedAt'][:10]}")
        print(f"   ğŸ”— ID: {playlist['id']}")
        
        # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå†…ã®å‹•ç”»æ•°ã‚’å–å¾—
        try:
            videos = yt.get_playlist_videos(playlist['id'], max_results=1)
            # æ­£ç¢ºãªå‹•ç”»æ•°ã‚’å–å¾—ã™ã‚‹ãŸã‚ã€ã•ã‚‰ã«è©³ç´°ã‚’å–å¾—
            all_videos = yt.get_playlist_videos(playlist['id'], max_results=200)
            print(f"   ğŸ“¹ å‹•ç”»æ•°: {len(all_videos)}")
        except YouTubeAPIError:
            print(f"   ğŸ“¹ å‹•ç”»æ•°: å–å¾—å¤±æ•—")
        
        # èª¬æ˜æ–‡ï¼ˆçŸ­ç¸®ç‰ˆï¼‰
        description = snippet.get('description', '')
        if description:
            print(f"   ğŸ“ èª¬æ˜: {description[:100]}...")
        
        print()

except YouTubeAPIError as e:
    if e.is_not_found():
        print("âŒ æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒãƒ£ãƒ³ãƒãƒ«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ§‹é€ åˆ†æ
def analyze_channel_playlists(channel_id: str):
    """ãƒãƒ£ãƒ³ãƒãƒ«ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ§‹é€ ã‚’åˆ†æ"""
    try:
        # ãƒãƒ£ãƒ³ãƒãƒ«åŸºæœ¬æƒ…å ±
        channel_info = yt.get_channel_info(channel_id)
        playlists = yt.get_channel_playlists(channel_id, max_results=100)
        
        print(f"=== {channel_info['snippet']['title']} ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ ===")
        print()
        
        total_playlist_videos = 0
        playlist_details = []
        
        # å„ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®è©³ç´°åˆ†æ
        for playlist in playlists:
            try:
                videos = yt.get_playlist_videos(playlist['id'], max_results=200)
                video_count = len(videos)
                total_playlist_videos += video_count
                
                playlist_details.append({
                    'title': playlist['snippet']['title'],
                    'video_count': video_count,
                    'created_date': playlist['snippet']['publishedAt'],
                    'id': playlist['id']
                })
                
            except YouTubeAPIError:
                continue
        
        # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’å‹•ç”»æ•°ã§ã‚½ãƒ¼ãƒˆ
        playlist_details.sort(key=lambda x: x['video_count'], reverse=True)
        
        # çµæœè¡¨ç¤º
        print(f"ğŸ“Š ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ•°: {len(playlists)}")
        print(f"ğŸ“¹ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå†…ç·å‹•ç”»æ•°: {total_playlist_videos}")
        print(f"ğŸ“ˆ å¹³å‡å‹•ç”»æ•°/ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {total_playlist_videos // len(playlists) if playlists else 0}")
        print()
        
        print("ğŸ” å‹•ç”»æ•°ä¸Šä½ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ:")
        for i, playlist in enumerate(playlist_details[:10], 1):
            print(f"  {i}. {playlist['title']}: {playlist['video_count']}æœ¬")
        
        # æœ€è¿‘ä½œæˆã•ã‚ŒãŸãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ
        recent_playlists = sorted(playlist_details, 
                                key=lambda x: x['created_date'], reverse=True)[:5]
        
        print("\nğŸ†• æœ€è¿‘ã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ:")
        for playlist in recent_playlists:
            date = playlist['created_date'][:10]
            print(f"  - {playlist['title']} ({date})")
        
        return playlist_details
        
    except YouTubeAPIError as e:
        print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ãƒãƒ£ãƒ³ãƒãƒ«åˆ†æã®å®Ÿè¡Œ
channel_analysis = analyze_channel_playlists("UC_x5XG1OV2P6uZZ5FSM9Ttw")

# ç‰¹å®šã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¤œç´¢
def find_playlists_by_keyword(channel_id: str, keywords: list):
    """ãƒãƒ£ãƒ³ãƒãƒ«å†…ã§ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‚’æ¤œç´¢"""
    try:
        playlists = yt.get_channel_playlists(channel_id)
        matched_playlists = []
        
        for playlist in playlists:
            title = playlist['snippet']['title'].lower()
            description = playlist['snippet'].get('description', '').lower()
            
            for keyword in keywords:
                if keyword.lower() in title or keyword.lower() in description:
                    matched_playlists.append({
                        'playlist': playlist,
                        'matched_keyword': keyword
                    })
                    break
        
        return matched_playlists
        
    except YouTubeAPIError as e:
        print(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®ä¾‹
keywords = ['å…¥é–€', 'åŸºç¤', 'tutorial', 'è¬›åº§', 'course']
matched = find_playlists_by_keyword("UC_x5XG1OV2P6uZZ5FSM9Ttw", keywords)

print(f"=== ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã—ãŸãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ ({len(matched)}ä»¶) ===")
for match in matched:
    playlist = match['playlist']
    keyword = match['matched_keyword']
    print(f"ğŸ“ {playlist['snippet']['title']}")
    print(f"   ğŸ” ãƒãƒƒãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
    print(f"   ğŸ”— ID: {playlist['id']}")
    print()
```

---

## ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½

YouTube.py3ã§ã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«å–å¾—ã™ã‚‹ãŸã‚ã®ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€APIã‚¯ã‚©ãƒ¼ã‚¿ã‚’ç¯€ç´„ã—ãªãŒã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æ®µéšçš„ã«å–å¾—ã§ãã¾ã™ã€‚

### search_videos_paginated()

```python
def search_videos_paginated(query: str, max_results: int = 50, order: str = "relevance", page_token: str = None) -> dict
```

ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã®å‹•ç”»æ¤œç´¢æ©Ÿèƒ½ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `query` (str): æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
- `max_results` (int): 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®æœ€å¤§çµæœæ•°ï¼ˆ1-50ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰
- `order` (str): ã‚½ãƒ¼ãƒˆé †åºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'relevance'ï¼‰
- `page_token` (str): æ¬¡ãƒšãƒ¼ã‚¸å–å¾—ç”¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

**æˆ»ã‚Šå€¤:**
```python
{
    'items': [...],  # æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
    'nextPageToken': 'token_string',  # æ¬¡ãƒšãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³
    'prevPageToken': 'token_string',  # å‰ãƒšãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    'pageInfo': {
        'totalResults': 1000000,  # ç·çµæœæ•°
        'resultsPerPage': 50      # 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®çµæœæ•°
    }
}
```

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
# åŸºæœ¬çš„ãªãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
def paginated_video_search(query: str, total_videos: int = 200):
    """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦å¤§é‡ã®å‹•ç”»ã‚’æ¤œç´¢"""
    all_videos = []
    next_page_token = None
    page_count = 0
    
    while len(all_videos) < total_videos:
        try:
            # 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Š50ä»¶å–å¾—
            remaining = min(50, total_videos - len(all_videos))
            
            result = yt.search_videos_paginated(
                query=query,
                max_results=remaining,
                page_token=next_page_token
            )
            
            # çµæœã‚’è¿½åŠ 
            all_videos.extend(result['items'])
            page_count += 1
            
            print(f"ãƒšãƒ¼ã‚¸ {page_count}: {len(result['items'])}ä»¶å–å¾— "
                  f"(ç´¯è¨ˆ: {len(all_videos)}ä»¶)")
            
            # æ¬¡ãƒšãƒ¼ã‚¸ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            next_page_token = result.get('nextPageToken')
            if not next_page_token:
                print("æœ€å¾Œã®ãƒšãƒ¼ã‚¸ã«åˆ°é”ã—ã¾ã—ãŸ")
                break
                
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            import time
            time.sleep(0.1)
            
        except YouTubeAPIError as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            break
    
    print(f"âœ… åˆè¨ˆ {len(all_videos)} ä»¶ã®å‹•ç”»ã‚’å–å¾—ã—ã¾ã—ãŸ")
    return all_videos

# ä½¿ç”¨ä¾‹
videos = paginated_video_search("Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", total_videos=500)

# é€²æ—è¡¨ç¤ºä»˜ãã®é«˜åº¦ãªä¾‹
def advanced_paginated_search(query: str, max_videos: int = 1000):
    """é€²æ—è¡¨ç¤ºã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãã®æ¤œç´¢"""
    videos = []
    next_token = None
    page = 0
    
    print(f"ğŸ” '{query}' ã®æ¤œç´¢ã‚’é–‹å§‹...")
    print(f"ğŸ“Š ç›®æ¨™å–å¾—æ•°: {max_videos}ä»¶")
    print("-" * 50)
    
    while len(videos) < max_videos:
        page += 1
        remaining = min(50, max_videos - len(videos))
        
        try:
            result = yt.search_videos_paginated(
                query=query,
                max_results=remaining,
                page_token=next_token
            )
            
            page_videos = result['items']
            videos.extend(page_videos)
            
            # é€²æ—è¡¨ç¤º
            progress = (len(videos) / max_videos) * 100
            print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page:2d}: {len(page_videos):2d}ä»¶ | "
                  f"ç´¯è¨ˆ {len(videos):4d}ä»¶ ({progress:5.1f}%)")
            
            # æ¬¡ãƒšãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯
            next_token = result.get('nextPageToken')
            if not next_token:
                print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã®çµæœã‚’å–å¾—ã—ã¾ã—ãŸ")
                break
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆ1ç§’ã‚ãŸã‚Š100ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™ï¼‰
            time.sleep(0.01)
            
        except YouTubeAPIError as e:
            if e.is_quota_exceeded():
                print("âŒ APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                print(f"ğŸ’¡ ç¾åœ¨ã¾ã§ã« {len(videos)} ä»¶å–å¾—æ¸ˆã¿")
                break
            else:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒç¶™ç¶šã—ã¾ã™: {e}")
                continue
    
    print("-" * 50)
    print(f"âœ… æ¤œç´¢å®Œäº†: {len(videos)} ä»¶å–å¾—")
    return videos
```

### get_playlist_videos_paginated()

```python
def get_playlist_videos_paginated(playlist_id: str, max_results: int = 50, page_token: str = None) -> dict
```

ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå‹•ç”»å–å¾—æ©Ÿèƒ½ã€‚

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
def get_full_playlist(playlist_id: str, max_videos: int = None):
    """ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®å…¨å‹•ç”»ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä½¿ç”¨ï¼‰"""
    all_videos = []
    next_token = None
    page = 0
    
    print(f"ğŸ“ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ {playlist_id} ã®å‹•ç”»ã‚’å–å¾—ä¸­...")
    
    while True:
        page += 1
        
        try:
            result = yt.get_playlist_videos_paginated(
                playlist_id=playlist_id,
                max_results=50,
                page_token=next_token
            )
            
            page_videos = result['items']
            all_videos.extend(page_videos)
            
            print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page}: {len(page_videos)}ä»¶å–å¾— "
                  f"(ç´¯è¨ˆ: {len(all_videos)}ä»¶)")
            
            # æœ€å¤§æ•°ãƒã‚§ãƒƒã‚¯
            if max_videos and len(all_videos) >= max_videos:
                all_videos = all_videos[:max_videos]
                print(f"ğŸ¯ ç›®æ¨™æ•° {max_videos} ã«åˆ°é”")
                break
            
            # æ¬¡ãƒšãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯
            next_token = result.get('nextPageToken')
            if not next_token:
                print("ğŸ“‹ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®æœ€å¾Œã«åˆ°é”")
                break
                
            time.sleep(0.05)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            
        except YouTubeAPIError as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            break
    
    return all_videos

# å¤§è¦æ¨¡ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®åˆ†æ
def analyze_large_playlist(playlist_id: str):
    """å¤§è¦æ¨¡ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®è©³ç´°åˆ†æ"""
    print("ğŸ“Š å¤§è¦æ¨¡ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåˆ†æã‚’é–‹å§‹...")
    
    # ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆåŸºæœ¬æƒ…å ±
    try:
        playlist_info = yt.get_playlist_info(playlist_id)
        print(f"ğŸ“ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {playlist_info['snippet']['title']}")
    except YouTubeAPIError:
        print("ğŸ“ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—")
    
    # å…¨å‹•ç”»ã‚’æ®µéšçš„ã«å–å¾—
    videos = get_full_playlist(playlist_id)
    
    if not videos:
        print("âŒ å‹•ç”»ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # åˆ†æãƒ‡ãƒ¼ã‚¿ã®åé›†
    channels = {}
    categories = {}
    total_duration = 0
    dates = []
    
    print("ğŸ” å‹•ç”»è©³ç´°ã‚’åˆ†æä¸­...")
    for i, video in enumerate(videos):
        try:
            video_id = video['snippet']['resourceId']['videoId']
            detail = yt.get_video_info(video_id)
            
            # ãƒãƒ£ãƒ³ãƒãƒ«é›†è¨ˆ
            channel = detail['snippet']['channelTitle']
            channels[channel] = channels.get(channel, 0) + 1
            
            # æ—¥ä»˜åé›†
            dates.append(detail['snippet']['publishedAt'])
            
            # é€²æ—è¡¨ç¤ºï¼ˆ100ä»¶ã”ã¨ï¼‰
            if (i + 1) % 100 == 0:
                progress = ((i + 1) / len(videos)) * 100
                print(f"  é€²æ—: {i + 1}/{len(videos)} ({progress:.1f}%)")
            
        except YouTubeAPIError:
            continue
    
    # åˆ†æçµæœã®è¡¨ç¤º
    print("\n=== åˆ†æçµæœ ===")
    print(f"ğŸ“¹ ç·å‹•ç”»æ•°: {len(videos)}")
    print(f"ğŸ“º é–¢é€£ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(channels)}")
    
    # ãƒˆãƒƒãƒ—ãƒãƒ£ãƒ³ãƒãƒ«
    top_channels = sorted(channels.items(), key=lambda x: x[1], reverse=True)[:10]
    print("\nğŸ” ä¸Šä½ãƒãƒ£ãƒ³ãƒãƒ«:")
    for i, (channel, count) in enumerate(top_channels, 1):
        print(f"  {i:2d}. {channel}: {count}æœ¬")
    
    # æœŸé–“åˆ†æ
    if dates:
        dates.sort()
        print(f"\nğŸ“… æœŸé–“: {dates[0][:10]} ï½ {dates[-1][:10]}")
    
    return {
        'total_videos': len(videos),
        'channels': channels,
        'date_range': (dates[0], dates[-1]) if dates else None
    }
```

### get_comments_paginated()

```python
def get_comments_paginated(video_id: str, max_results: int = 100, page_token: str = None) -> dict
```

ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã®ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—æ©Ÿèƒ½ã€‚

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
def get_all_comments(video_id: str, max_comments: int = 1000):
    """å‹•ç”»ã®å…¨ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä½¿ç”¨ï¼‰"""
    all_comments = []
    next_token = None
    page = 0
    
    print(f"ğŸ’¬ å‹•ç”» {video_id} ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­...")
    
    while len(all_comments) < max_comments:
        page += 1
        remaining = min(100, max_comments - len(all_comments))
        
        try:
            result = yt.get_comments_paginated(
                video_id=video_id,
                max_results=remaining,
                page_token=next_token
            )
            
            page_comments = result['items']
            all_comments.extend(page_comments)
            
            print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page}: {len(page_comments)}ä»¶ "
                  f"(ç´¯è¨ˆ: {len(all_comments)}ä»¶)")
            
            next_token = result.get('nextPageToken')
            if not next_token:
                print("ğŸ“‹ ã™ã¹ã¦ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")
                break
                
            time.sleep(0.1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            
        except YouTubeAPIError as e:
            if e.is_forbidden():
                print("âŒ ã‚³ãƒ¡ãƒ³ãƒˆãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
                break
            else:
                print(f"ã‚¨ãƒ©ãƒ¼: {e}")
                break
    
    return all_comments

# ã‚³ãƒ¡ãƒ³ãƒˆæ„Ÿæƒ…åˆ†æï¼ˆå¤§è¦æ¨¡ï¼‰
def analyze_comments_sentiment(video_id: str):
    """å¤§é‡ã®ã‚³ãƒ¡ãƒ³ãƒˆã®æ„Ÿæƒ…åˆ†æ"""
    comments = get_all_comments(video_id, max_comments=5000)
    
    if not comments:
        print("ã‚³ãƒ¡ãƒ³ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # æ„Ÿæƒ…åˆ†æç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    positive_keywords = [
        'è‰¯ã„', 'ã„ã„', 'ã™ã”ã„', 'ç´ æ™´ã‚‰ã—ã„', 'æœ€é«˜', 'æ„Ÿå‹•',
        'ã‚ã‚ŠãŒã¨ã†', 'åŠ©ã‹ã£ãŸ', 'å‹‰å¼·ã«ãªã‚‹', 'åˆ†ã‹ã‚Šã‚„ã™ã„'
    ]
    
    negative_keywords = [
        'æ‚ªã„', 'ã ã‚', 'ã¤ã¾ã‚‰ãªã„', 'åˆ†ã‹ã‚‰ãªã„', 'é›£ã—ã„',
        'ã‚¤ãƒã‚¤ãƒ', 'å¾®å¦™', 'æœŸå¾…å¤–ã‚Œ'
    ]
    
    # æ„Ÿæƒ…åˆ†é¡
    positive_count = 0
    negative_count = 0
    neutral_count = 0
    
    for comment in comments:
        text = comment['snippet']['topLevelComment']['snippet']['textDisplay'].lower()
        
        is_positive = any(keyword in text for keyword in positive_keywords)
        is_negative = any(keyword in text for keyword in negative_keywords)
        
        if is_positive and not is_negative:
            positive_count += 1
        elif is_negative and not is_positive:
            negative_count += 1
        else:
            neutral_count += 1
    
    total = len(comments)
    print(f"\n=== ã‚³ãƒ¡ãƒ³ãƒˆæ„Ÿæƒ…åˆ†æçµæœ ===")
    print(f"ğŸ’¬ ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°: {total}")
    print(f"ğŸ˜Š ãƒã‚¸ãƒ†ã‚£ãƒ–: {positive_count} ({positive_count/total*100:.1f}%)")
    print(f"ğŸ˜ ãƒã‚¬ãƒ†ã‚£ãƒ–: {negative_count} ({negative_count/total*100:.1f}%)")
    print(f"ğŸ˜ ä¸­ç«‹: {neutral_count} ({neutral_count/total*100:.1f}%)")
    
    return {
        'total': total,
        'positive': positive_count,
        'negative': negative_count,
        'neutral': neutral_count
    }
```

### get_channel_videos_paginated()

```python
def get_channel_videos_paginated(channel_id: str, max_results: int = 50, page_token: str = None) -> dict
```

ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œã®ãƒãƒ£ãƒ³ãƒãƒ«å‹•ç”»å–å¾—æ©Ÿèƒ½ã€‚

**è©³ç´°ãªä½¿ç”¨ä¾‹:**
```python
def get_all_channel_videos(channel_id: str):
    """ãƒãƒ£ãƒ³ãƒãƒ«ã®å…¨å‹•ç”»ã‚’å–å¾—"""
    all_videos = []
    next_token = None
    page = 0
    
    try:
        # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’å–å¾—
        channel_info = yt.get_channel_info(channel_id)
        channel_name = channel_info['snippet']['title']
        total_videos = int(channel_info['statistics']['videoCount'])
        
        print(f"ğŸ“º {channel_name} ã®å‹•ç”»ã‚’å–å¾—ä¸­...")
        print(f"ğŸ“Š ç·å‹•ç”»æ•°: {total_videos}")
        print("-" * 50)
        
    except YouTubeAPIError:
        print("ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã®å–å¾—ã«å¤±æ•—")
        return []
    
    while True:
        page += 1
        
        try:
            result = yt.get_channel_videos_paginated(
                channel_id=channel_id,
                max_results=50,
                page_token=next_token
            )
            
            page_videos = result['items']
            all_videos.extend(page_videos)
            
            progress = (len(all_videos) / total_videos) * 100
            print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page:2d}: {len(page_videos):2d}ä»¶ | "
                  f"ç´¯è¨ˆ {len(all_videos):4d}ä»¶ ({progress:5.1f}%)")
            
            next_token = result.get('nextPageToken')
            if not next_token:
                print("ğŸ“‹ ã™ã¹ã¦ã®å‹•ç”»ã‚’å–å¾—ã—ã¾ã—ãŸ")
                break
                
            time.sleep(0.05)
            
        except YouTubeAPIError as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            break
    
    return all_videos

# ãƒãƒ£ãƒ³ãƒãƒ«ã®æˆé•·åˆ†æ
def analyze_channel_growth_over_time(channel_id: str):
    """ãƒãƒ£ãƒ³ãƒãƒ«ã®æ™‚ç³»åˆ—æˆé•·åˆ†æ"""
    videos = get_all_channel_videos(channel_id)
    
    if not videos:
        return
    
    # å‹•ç”»ã‚’å…¬é–‹æ—¥ã§ã‚½ãƒ¼ãƒˆ
    videos_with_dates = []
    
    print("ğŸ“Š å‹•ç”»è©³ç´°ã‚’å–å¾—ä¸­...")
    for i, video in enumerate(videos):
        try:
            video_detail = yt.get_video_info(video['id']['videoId'])
            videos_with_dates.append({
                'date': video_detail['snippet']['publishedAt'],
                'views': int(video_detail['statistics']['viewCount']),
                'title': video_detail['snippet']['title']
            })
            
            if (i + 1) % 50 == 0:
                print(f"  é€²æ—: {i + 1}/{len(videos)}")
                
        except YouTubeAPIError:
            continue
    
    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
    videos_with_dates.sort(key=lambda x: x['date'])
    
    # æœˆåˆ¥é›†è¨ˆ
    from collections import defaultdict
    monthly_data = defaultdict(list)
    
    for video in videos_with_dates:
        month = video['date'][:7]  # YYYY-MM
        monthly_data[month].append(video)
    
    print("\n=== æœˆåˆ¥å‹•ç”»æŠ•ç¨¿åˆ†æ ===")
    print(f"{'æœˆ':<10} {'å‹•ç”»æ•°':<6} {'å¹³å‡å†ç”Ÿæ•°':<12} {'æœ€é«˜å†ç”Ÿæ•°':<12}")
    print("-" * 50)
    
    for month in sorted(monthly_data.keys()):
        videos_in_month = monthly_data[month]
        avg_views = sum(v['views'] for v in videos_in_month) / len(videos_in_month)
        max_views = max(v['views'] for v in videos_in_month)
        
        print(f"{month:<10} {len(videos_in_month):<6} {avg_views:>10,.0f} {max_views:>10,}")
```

### ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä½¿ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```python
class PaginationHelper:
    """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, youtube_api):
        self.yt = youtube_api
        self.request_count = 0
        self.start_time = time.time()
    
    def get_all_results(self, search_function, *args, max_total=None, **kwargs):
        """æ±ç”¨çš„ãªãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†"""
        all_results = []
        next_token = None
        page = 0
        
        while True:
            page += 1
            self.request_count += 1
            
            try:
                # ãƒšãƒ¼ã‚¸ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                if 'page_token' in kwargs:
                    kwargs['page_token'] = next_token
                else:
                    kwargs = {**kwargs, 'page_token': next_token}
                
                result = search_function(*args, **kwargs)
                
                # çµæœã‚’è¿½åŠ 
                page_results = result['items']
                all_results.extend(page_results)
                
                # é€²æ—è¡¨ç¤º
                elapsed = time.time() - self.start_time
                rate = self.request_count / elapsed if elapsed > 0 else 0
                
                print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page}: {len(page_results)}ä»¶ | "
                      f"ç´¯è¨ˆ: {len(all_results)}ä»¶ | "
                      f"ãƒ¬ãƒ¼ãƒˆ: {rate:.1f}req/s")
                
                # åˆ¶é™ãƒã‚§ãƒƒã‚¯
                if max_total and len(all_results) >= max_total:
                    all_results = all_results[:max_total]
                    print(f"ğŸ¯ åˆ¶é™æ•° {max_total} ã«åˆ°é”")
                    break
                
                # æ¬¡ãƒšãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯
                next_token = result.get('nextPageToken')
                if not next_token:
                    print("ğŸ“‹ æœ€å¾Œã®ãƒšãƒ¼ã‚¸ã«åˆ°é”")
                    break
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                self._rate_limit()
                
            except YouTubeAPIError as e:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
                if e.is_quota_exceeded():
                    print("âŒ ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                    break
                elif e.is_forbidden():
                    print("âŒ ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
                    break
                else:
                    print("ğŸ”„ ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ã—ã¦ç¶™ç¶šã—ã¾ã™")
                    continue
        
        return all_results
    
    def _rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–"""
        # YouTube API ã¯1ç§’ã‚ãŸã‚Š100ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§
        elapsed = time.time() - self.start_time
        if elapsed > 0:
            current_rate = self.request_count / elapsed
            if current_rate > 90:  # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
                sleep_time = (self.request_count / 90) - elapsed
                if sleep_time > 0:
                    time.sleep(sleep_time)

# ä½¿ç”¨ä¾‹
helper = PaginationHelper(yt)

# å¤§é‡ã®å‹•ç”»æ¤œç´¢
videos = helper.get_all_results(
    yt.search_videos_paginated,
    "Python æ©Ÿæ¢°å­¦ç¿’",
    max_results=50,
    max_total=1000
)

# ãƒãƒ£ãƒ³ãƒãƒ«ã®å…¨å‹•ç”»å–å¾—
channel_videos = helper.get_all_results(
    yt.get_channel_videos_paginated,
    "UC_x5XG1OV2P6uZZ5FSM9Ttw",
    max_results=50
)

print(f"ğŸ“Š APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç·æ•°: {helper.request_count}")
print(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {time.time() - helper.start_time:.1f}ç§’")
```

---

**æœ€çµ‚æ›´æ–°**: 2024å¹´12æœˆ
**é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [README](README.md) | [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰](installation.md) | [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](troubleshooting.md)